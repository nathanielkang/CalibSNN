# CalibSNN - Minimal Implementation

This is a minimal implementation of **CalibSNN** (Calibrated Soft Nearest Neighbor Loss) for Federated Learning with non-IID data, as described in the paper "Re-sampling Calibrated SNN Loss: A Robust Approach to Non-IID Data in Federated Learning".

## ğŸš€ Quick Start

### Prerequisites

Install required dependencies:
```bash
pip install torch torchvision pandas numpy scikit-learn
```

### Essential Files Structure

```
CalibSNN/
â”œâ”€â”€ main.py                      # Main federated learning runner
â”œâ”€â”€ conf.py                      # Configuration and hyperparameters
â”œâ”€â”€ run_CalibSNN.py             # Experiment runner script
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ utils.py                     # Utility functions
â”œâ”€â”€ data_process.py              # Data processing utilities
â”œâ”€â”€ prepare_data.py              # Data preparation
â”‚
â”œâ”€â”€ loss_function/               # Core CalibSNN components
â”‚   â”œâ”€â”€ snn_loss.py             # SNN loss implementation
â”‚   â”œâ”€â”€ calibration.py          # Feature calibration
â”‚   â”œâ”€â”€ calibrated_loss.py      # Combined loss wrapper
â”‚   â””â”€â”€ select_loss_fn.py       # Loss function selector
â”‚
â””â”€â”€ fedavg/                     # Federated learning framework
    â”œâ”€â”€ client_calibsnn.py      # CalibSNN client
    â”œâ”€â”€ server.py               # FL server
    â”œâ”€â”€ models.py               # Neural network models
    â””â”€â”€ datasets.py             # Dataset handling
```

## ğŸ“‹ How to Run Experiments

### Option 1: Simple Run (using main.py)
```bash
python main.py
```

### Option 2: Experimental Run (using run_CalibSNN.py)
```bash
# Run on all datasets with default parameters
python run_CalibSNN.py

# Run on specific datasets
python run_CalibSNN.py --datasets mnist cifar10

# Run with custom parameters
python run_CalibSNN.py \
    --datasets mnist \
    --betas 0.05 0.1 0.3 \
    --num_clients 20 \
    --num_rounds 50 \
    --tau 2.5 \
    --lambda_snn 0.5
```

### Option 3: Quick Test Mode
```bash
python run_CalibSNN.py --test_mode
```

## âš™ï¸ Key Configuration Parameters

Edit `conf.py` to customize:

### CalibSNN Specific
- `'--tau': 2.5` - Temperature parameter for SNN loss
- `'lambda_snn': 0.5` - Weight for SNN loss component
- `'calibsnn.enable_calibration': True` - Enable feature calibration
- `'calibsnn.enable_resampling': True` - Enable re-sampling
- `'calibsnn.resample_ratio': 0.2` - Ratio of synthetic samples

### Federated Learning
- `'num_parties': 20` - Number of clients
- `'global_epochs': 50` - Communication rounds
- `'local_epochs': 10` - Local training epochs
- `'beta': 0.05` - Non-IID level (lower = more heterogeneous)

### Dataset & Model
- `'dataset_used': "cifar10"` - Dataset (mnist, cifar10, usps)
- `'model_name': "cnn"` - Model architecture
- `'batch_size': 1024` - Batch size
- `'lr': 0.01` - Learning rate

## ğŸ“Š Supported Datasets

Prepare datasets using:
```bash
# Prepare specific dataset
python prepare_data.py --datasets mnist

# Prepare multiple datasets  
python prepare_data.py --datasets mnist cifar10 usps
```

Supported datasets:
- **MNIST**: Handwritten digits (28x28 grayscale)
- **CIFAR-10**: Natural images (32x32 color)
- **USPS**: Postal handwritten digits (16x16 grayscale)

## ğŸ”§ Core CalibSNN Components

### 1. SNN Loss (`loss_function/snn_loss.py`)
Implements the Soft Nearest Neighbor loss:
- Encourages intra-class compactness
- Promotes inter-class separation
- Temperature parameter Ï„ controls concentration

### 2. Feature Calibration (`loss_function/calibration.py`)
Handles distribution alignment:
- Computes local mean Î¼_{k,c} and covariance Î£_{k,c}
- Aggregates global statistics Î¼_c and Î£_c
- Calibrates features to match global distribution

### 3. CalibSNN Client (`fedavg/client_calibsnn.py`)
Integrates calibration with local training:
- Computes local statistics
- Applies feature calibration
- Trains with combined CE + SNN loss

## ğŸ“ˆ Output Structure

Results are saved in:
```
experiments/
â””â”€â”€ CalibSNN_[dataset]_beta[value]_C[clients]_R[rounds]_[timestamp]/
    â”œâ”€â”€ config.json              # Experiment configuration
    â”œâ”€â”€ round_metrics.csv        # Per-round metrics
    â””â”€â”€ final_model.pth          # Trained model
```

## ğŸ” Key Differences from Standard FL

| Aspect | Standard FL | CalibSNN |
|--------|-------------|----------|
| Loss Function | Cross-entropy only | CE + SNN loss |
| Data Handling | Raw local data | Calibrated features |
| Aggregation | Model parameters only | Parameters + statistics |
| Non-IID Handling | Limited | Feature-level calibration |

## ğŸ¯ Expected Results

CalibSNN typically achieves:
- **Better accuracy** under non-IID conditions
- **Faster convergence** (2-4x speedup)
- **More robust features** across heterogeneous clients
- **Improved performance** especially at low Î² values (high heterogeneity)

## ğŸ“ Citation

If you use this code, please cite:
```bibtex
@article{calibsnn2024,
  title={Re-sampling Calibrated SNN Loss: A Robust Approach to Non-IID Data in Federated Learning},
  author={Kang, Nathaniel and Im, Jongho},
  year={2024}
}
```

## ğŸ› ï¸ Troubleshooting

### Common Issues

1. **Numerical Instability**: Increase `tau` parameter (e.g., 3.0)
2. **Out of Memory**: Reduce `batch_size` or `num_clients`
3. **Slow Training**: Reduce `local_epochs` or disable resampling
4. **NaN Values**: Decrease `lambda_snn` (e.g., 0.1)

### Quick Fixes
```bash
# Conservative parameters for stability
python run_CalibSNN.py --tau 3.0 --lambda_snn 0.1 --learning_rate 0.005

# CPU-only mode
python run_CalibSNN.py --gpu_id -1

# Quick test
python run_CalibSNN.py --test_mode --num_rounds 10
``` 